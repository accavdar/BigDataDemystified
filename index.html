<!doctype html>
<html lang="en" xmlns="http://www.w3.org/1999/html">
<head>
    <meta charset="utf-8">

    <title>Big Data Demystified</title>

    <meta name="description" content="Big Data Demystified Presentation">
    <meta name="author" content="Abdullah Cetin CAVDAR">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="reveal/css/reveal.min.css">
    <link rel="stylesheet" href="reveal/css/theme/night.css" id="theme">
    <link rel="stylesheet" href="css/style.css">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="reveal/lib/css/zenburn.css">

    <!-- If the query includes 'print-pdf', use the PDF print sheet -->
    <script>
        document.write('<link rel="stylesheet" href="reveal/css/print/' + ( window.location.search.match(/print-pdf/gi) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">');
    </script>

    <!--[if lt IE 9]>
    <script src="reveal/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
    <h1>Big Data</h1>

    <h1>Demystified</h1>

    <h3>December, 2013</h3>

    <p>
        <a href="http://cavdar.net" target="_blank">Abdullah Cetin CAVDAR</a> / <a
            href="http://twitter.com/accavdar" target="_blank">@accavdar</a>
    </p>
</section>

<section>
    <section>
        <h1>Concepts</h1>
    </section>

    <section>
        <h2>What's Big Data</h2>
        <blockquote>
            <span class="focus">Big data</span> is data that exceeds the processing capacity of conventional
            database systems.
        </blockquote>
    </section>

    <section>
        <h2>4V's of Big Data</h2>
        <ul>
            <li class="fragment roll-in"><span class="focus">Volume</span> data is getting higher/bigger than ever</li>
            <li class="fragment roll-in"><span class="focus">Velocity</span> data is increasing. ex: complex real time
                data
            </li>
            <li class="fragment roll-in"><span class="focus">Variety</span> data is spiraling ex: unstructured video and
                voice
            </li>
            <li class="fragment roll-in"><span class="focus">Variability</span> data types/formats also different</li>
        </ul>
    </section>

    <section>
        <h2>Multitude of Data Types</h2>
        <ul>
            <li class="fragment roll-in">
                <span class="focus">Structured</span>, <span class="focus">Semi-structured</span> and <span class="focus">Unstructured</span>
                <ul>
                    <li>Demographic, psychographic, transactional</li>
                    <li>Call center data, social media data, web log data, sensor networks</li>
                    <li>Requires new storage mechanisms (Hadoop, NoSQL, ...)</li>
                    <li>High dimensionality</li>
                </ul>
            </li>
        </ul>
    </section>

    <section>
        <h2>Different Sectors</h2>
        <img src="img/data_by_sector.png"/>
    </section>

    <section>
        <h2>Challenge</h2>

        <p>The challenge in big data analytics is to <span
                class="focus">dig deeply, quickly (real time?) and widely</span></p>
    </section>

    <section>
        <h1>Real Challenge: Stream Mining?</h1>
    </section>

    <section>
        <h1>Stream Mining Usages</h1>
    </section>

    <section>
        <h2><span class="focus">Generate Summaries</span></h2>

        <p>Properly constructed summaries are useful for highlighting <span class="focus">emerging patterns, trends, and anomalies</span>.
            Common summaries include a list of distinct items, recently trending items, heavy hitters (items that have
            appeared frequently), and the top k (most
            popular) items</p>
    </section>

    <section>
        <h2><span class="focus">Approximate Answers</span></h2>

        <p>In the streaming context summaries are constantly changing, thus in many applications approximate
            answers are acceptable</p>
    </section>

    <section>
        <h2><span class="focus">Sampling from a Data Stream</span></h2>

        <p>Building a random sample from data that’s continuously arriving isn’t straightforward (note that in a
            stream you <span class="focus">iterate</span> over the data set only once)</p>
    </section>

    <section>
        <h2><span class="focus">Data Mining</span></h2>

        <p>Beyond simple summaries, advanced algorithms for data mining have drawn interest</p>
    </section>

    <section>
        <h2>Application Areas</h2>

        <p>Important stream mining applications such as</p>
        <ul>
            <li class="fragment roll-in"><span class="focus">identifying trends (discover “trending topics”)</span></li>
            <li class="fragment roll-in"><span class="focus">anomaly detection (“alerts”)</span></li>
            <li class="fragment roll-in"><span class="focus">correlations</span></li>
            <li class="fragment roll-in"><span class="focus">clustering</span></li>
            <li class="fragment roll-in"><span class="focus">classification</span></li>
        </ul>
    </section>

    <section>
        <h1>Purpose</h1>

        <p>You have to be able to reliably <span class="focus">consume it, normalize it, merge it with other data, apply functions
            on it, store it, query it, distribute it</span></p>
    </section>

    <section>
        <h2>Cyber Security?</h2>
        <img src="img/cyber_security.png"/>
    </section>

</section>

<section>
    <section>
        <h1>NoSQL</h1>
    </section>

    <section>
        <h2>NoSQL</h2>
        <ul>
            <li class="fragment roll-in"><span class="focus">N</span>ot <span class="focus">O</span>nly <span
                    class="focus">SQL</span></li>
            <li class="fragment roll-in">Usually do not require a fixed table schema nor do they use the concept
                of joins
            </li>
            <li class="fragment roll-in">
                Offers BASE instead of ACID (Atomicity, Consistency, Isolation, Durability)
                <ul>
                    <li><span class="focus">BA</span>siclly available</li>
                    <li><span class="focus">S</span>oft state (scalable)</li>
                    <li><span class="focus">E</span>ventual Consistency</li>
                </ul>
            </li>
        </ul>
    </section>

    <section>
        <h2>What's wrong with RDBMS?</h2>
        <ul>
            <li class="fragment roll-in">One size fits all? Not really</li>
            <li class="fragment roll-in">Rigid schema design</li>
            <li class="fragment roll-in">Harder to scale</li>
            <li class="fragment roll-in">Replication</li>
            <li class="fragment roll-in">Joins across multiple nodes? Hard</li>
            <li class="fragment roll-in">How does RDBMS handle data growth? Hard</li>
        </ul>
    </section>

    <section>
        <h2>Advantages</h2>
        <ul>
            <li class="fragment roll-in">Flexible schema</li>
            <li class="fragment roll-in">Massive scalability</li>
            <li class="fragment roll-in">
                Eventual consistency
                <ul>
                    <li>higher performance</li>
                    <li>availability</li>
                </ul>
            </li>
        </ul>
    </section>

    <section>
        <h2>Disadvantages</h2>
        <ul>
            <li class="fragment roll-in">No declarative query language
                <ul>
                    <li>Requires more programming</li>
                </ul>
            </li>
            <li class="fragment roll-in">
                Eventual consistency
                <ul>
                    <li>Fewer guarantees</li>
                </ul>
            </li>
        </ul>
    </section>

    <section>
        <h2>NoSQL Systems</h2>
        <ul>
            <li class="fragment roll-in">Column Family</li>
            <li class="fragment roll-in">Key-Value Stores</li>
            <li class="fragment roll-in">Document Stores</li>
            <li class="fragment roll-in">Graph Databases</li>
        </ul>
    </section>

    <section>
        <h2>Column Family</h2>
        <ul>
            <li class="fragment roll-in">
                Each storage block contains data from only one column
            </li>
            <li class="fragment roll-in">
                More efficient than row (or document) store if:
                <ul>
                    <li>Multiple row/record/documents are inserted at the same time so updates of column blocks can be
                        aggregated
                    </li>
                    <li>Retrievals access only some of the columns in a row/record/document</li>
                </ul>
            </li>
            <li class="fragment roll-in"><span class="focus">HBase</span>, <span class="focus">Cassandra</span>, ...
            </li>
        </ul>
    </section>

    <section>
        <h2>Key-Value Stores</h2>
        <ul>
            <li class="fragment roll-in">
                Extremely simple Interface
                <ul>
                    <li class="fragment roll-in">Data model: <span class="focus">(key, value)</span> pairs</li>
                </ul>
            </li>
            <li class="fragment roll-in">
                Operations
                <ul>
                    <li>Insert(key, value)</li>
                    <li>Fetch(key)</li>
                    <li>Update(key)</li>
                    <li>Delete(key)</li>
                </ul>
            </li>
            <li class="fragment roll-in">
                Implementation: <span class="focus">efficiency</span>, <span class="focus">scalability</span>, <span
                    class="focus">fault-tolerance</span>
                <ul>
                    <li>Records distributed to nodes based on key</li>
                    <li>Replication</li>
                    <li>Single-record transactions, <span class="focus">eventual consistency</span></li>
                </ul>
            </li>
            <li class="fragment roll-in"><span class="focus">Amazon Dynamo</span>, <span class="focus">Redis</span>,
                <span class="focus">Riak</span>, ...
            </li>
        </ul>
    </section>

    <section>
        <h2>Document Stores</h2>
        <ul>
            <li class="fragment roll-in">
                Like Key-Value Stores except value is document
                <ul>
                    <li class="fragment roll-in">Data model: <span class="focus">(key, document)</span> pairs</li>
                    <li class="fragment roll-in">Document: JSON, XML, other semi-structured formats</li>
                </ul>
            </li>
            <li class="fragment roll-in">
                Operations
                <ul>
                    <li>Insert(key, document)</li>
                    <li>Fetch(key)</li>
                    <li>Update(key)</li>
                    <li>Delete(key)</li>
                    <li>Also fetch based on document contents</li>
                </ul>
            </li>
            <li class="fragment roll-in"><span class="focus">Apache CouchDB</span>, <span class="focus">MongoDB</span>,
                <span class="focus">Elastic Search</span>, ...
            </li>
        </ul>

    </section>

    <section>
        <h2>Graph Databases</h2>
        <ul>
            <li class="fragment roll-in">
                <span class="focus">A graph</span> is a collection nodes (things) and edges (relationships) that connect
                pairs of nodes
            </li>

            <li class="fragment roll-in">
                Attach properties (key-value pairs) on nodes and relationships
            </li>

            <li class="fragment roll-in">
                Relationships connect two nodes and both nodes and relationships can hold an arbitrary amount of
                key-value pairs
            </li>

            <li class="fragment roll-in">
                A graph database can be thought of as a key-value store, with full support for relationships
            </li>

            <li class="fragment roll-in"><span class="focus">Neo4j</span>, <span class="focus">FlockDB</span>,
                <span class="focus">Pregel</span>, ...
            </li>
        </ul>
    </section>
</section>

<section>
<section>
    <h1>Batch Processing</h1>
</section>

<section>
    <h2>Batch Processing</h2>
    <ul>
        <li class="fragment roll-in">
            <span class="focus">Batch data processing</span> is an efficient way of processing high volumes of data
            is where a group of
            transactions is collected over a period of time
        </li>
        <li class="fragment roll-in">
            Data is collected, entered, processed and then the batch results are produced
        </li>
        <li class="fragment roll-in">
            Data is processed by <span class="focus">worker nodes</span> and managed by <span
                class="focus">master node</span>
        </li>
        <li class="fragment roll-in">
            Analytical queries can be executed as distributed on offline big data. User queries are converted to
            Map-Reduce jobs on cluster to process big data
            <ul>
                <li><span class="focus">Hive</span>: Supports SQL like query language</li>
                <li><span class="focus">Pig</span>: More likely a scripting language</li>
            </ul>
        </li>
    </ul>
</section>

<section>
    <h2>Map-Reduce</h2>
    <ul>
        <li class="fragment roll-in">
            <span class="focus">MapReduce</span> is a programming model and software framework first developed by
            Google
        </li>
        <li class="fragment roll-in">
            A method for distributing a task across multiple nodes
        </li>
        <li class="fragment roll-in">
            Each node processes data assigned to that node
        </li>
        <li class="fragment roll-in">
            Consists of two developer-created phases
            <ul>
                <li><span class="focus">Map</span></li>
                <li><span class="focus">Reduce</span></li>
            </ul>
        </li>
        <li class="fragment roll-in">
            Features of MapReduce systems include:
            <ul>
                <li>Reliably processing a job even when machines die</li>
                <li>Paralellization on thousands of machines</li>
            </ul>
        </li>
    </ul>
</section>

<section>
    <h2>Map</h2>

    <p><span class="focus">Map step</span>: The master node takes the input, divides it into smaller sub-problems,
        and distributes them to
        worker nodes. A worker node may do this again in turn, leading to a multi-level tree structure. The worker
        node processes the smaller problem, and passes the answer back to its master node</p>
<pre>
<code class="java" contenteditable="false" data-trim>
    function map(String name, String document) {
    for each word w in document {
    emit (w, 1) // emit(key, value)
    }
    }
</code>
</pre>
</section>

<section>
    <h2>Reduce</h2>

    <p><span class="focus">Reduce step</span>: After map step, the master node collects the answers of all the
        sub-problems and classifies all values with their keys. Each unique key and its values are sent to a
        distinct reducer. This means that each reducer processes a distinct key and its values independently from
        each other</p>
<pre>
<code class="java" contenteditable="false" data-trim>
    function reduce(String word, Iterator partialCounts) {
    sum = 0;
    for each pc in partialCounts {
    sum += ParseInt(pc);
    emit (word, sum);
    }
    }
</code>
</pre>
</section>

<section>
    <h2>MapReduce Overview</h2>
    <img src="img/mapreduce.png"/>
</section>

<section>
    <h2>Hadoop</h2>
    <ul>
        <li class="fragment roll-in">
            <span class="focus">Hadoop</span> is a scalable fault-tolerant distributed system for data storage and
            processing
        </li>
        <li class="fragment roll-in">
            Core Hadoop has two main components:
            <ul>
                <li><span class="focus">HDFS</span>: Hadoop Distributed File System is a reliable, self- healing,
                    redundant, high-bandwidth, distributed file system optimized for large files
                </li>
                <li><span class="focus">MapReduce</span>: Fault-tolerant distributed processing</li>
            </ul>
        </li>
        <li class="fragment roll-in">
            Operates on unsuctured and structured data
        </li>
    </ul>
</section>

<section>
    <h2>HDFS</h2>
    <ul>
        <li class="fragment roll-in">
            Scalable, distributed, portable file system written in Java for Hadoop framework
            <ul>
                <li>Primary distributed storage used by Hadoop applications</li>
            </ul>
        </li>
        <li class="fragment roll-in">
            HDFS can be part of a Hadoop cluster or can be a stand-alone general purpose distributed file system
        </li>
        <li class="fragment roll-in">
            An HDFS cluster primarily consists of
            <ul>
                <li><span class="focus">NameNode</span> that manages file system metadata</li>
                <li><span class="focus">DataNode</span> that stores actual data</li>
            </ul>
        </li>
        <li class="fragment roll-in">
            Stores very large files in blocks across machines in a large cluster
            <ul>
                <li>Reliability and fault tolerance ensured by replicating data across multiple hosts</li>
            </ul>
        </li>
    </ul>
</section>

<section>
    <h2>Analytical Queries over Offline Big Data</h2>
    <ul>
        <li class="fragment roll-in">
            Hadoop is great for large-data processing
            <ul>
                <li>But writing Java programs for everything is verbose and slow</li>
                <li>Not everyone wants to (or can) write Java code</li>
            </ul>
        </li>
        <li class="fragment roll-in">
            Solution: develop higher-level data processing languages
            <ul>
                <li><span class="focus">Hive</span> HQL is like SQL</li>
                <li><span class="focus">Pig</span> Pig Latin is a bit like Perl</li>
            </ul>
        </li>
    </ul>
</section>

<section>
    <h2>Hive</h2>
    <ul>
        <li class="fragment roll-in">
            A system for querying and managing structured data built on top of Hadoop
        </li>
        <li class="fragment roll-in">
            Structured data with rich data types (structs, lists and maps)
        </li>
        <li class="fragment roll-in">
            Directly query data from different formats (text/binary) and file formats (Flat/Sequence)
        </li>
        <li class="fragment roll-in">
            SQL as a familiar programming tool and for standard analytics
        </li>
        <li class="fragment roll-in">
            Allow embedded scripts for extensibility and for non standard applications
        </li>
        <li class="fragment roll-in">
            Rich MetaData to allow data discovery and for optimization
        </li>
    </ul>
</section>

<section>
    <h2>Pig</h2>
    <ul>
        <li class="fragment roll-in">
            A platform for analyzing large data sets that consists of a high-level language for expressing data analysis
            programs
        </li>
        <li class="fragment roll-in">
            Compiles down to MapReduce jobs
        </li>
        <li class="fragment roll-in">
            Common design patterns as key words (joins, distinct, counts)
        </li>
        <li class="fragment roll-in">
            Data flow analysis
            <ul>
                <li>A script can map to multiple map-reduce jobs</li>
            </ul>
        </li>
        <li class="fragment roll-in">
            Can be interactive mode
            <ul>
                <li>Issue commands and get results</li>
            </ul>

        </li>
    </ul>
</section>

</section>

<section>
    <section>
        <h1>Real Time Data Processing</h1>
    </section>

    <section>
        <h2>Real Time Data Processing</h2>
        <ul>
            <li class="fragment roll-in">
                In contrast, real time data processing involves a continual input, process and output of data
            </li>
            <li class="fragment roll-in">
                Size of data is not certain at the beginning of the processing
            </li>
            <li class="fragment roll-in">
                Data must be processed in a small time period (or near real time)
            </li>
            <li class="fragment roll-in">
                <span class="focus">Storm</span> is a most popular open source implementation of realtime data
                processing
            </li>
        </ul>
    </section>

    <section>
        <h2>Storm</h2>
        <ul>
            <li class="fragment roll-in">
                Storm is a highly distributed real time computation system
            </li>
            <li class="fragment roll-in">
                It's scalable and fault-tolerant
            </li>
            <li class="fragment roll-in">
                Can be used with any programming language
            </li>
        </ul>
    </section>

    <section>
        <h2>Architecture</h2>
        <img src="img/storm_architecture.png"/>
    </section>

    <section>
        <h2>Architecture Components</h2>
        <ul>
            <li class="fragment roll-in">
                <span class="focus">Nimbus</span>
                <ul>
                    <li>Master node (similar to Hadoop JobTracker)</li>
                    <li>Responsible for distributing code around the cluster, assigning tasks to machines, and
                        monitoring for failures
                    </li>
                </ul>
            </li>
            <li class="fragment roll-in">
                <span class="focus">Zookeeper</span>
                <ul>
                    <li>Used for cluster coordination between Nimbus and Supervisors</li>
                    <li>Nimbus and Supervisors are fail-fast and stateless; all state is kept in Zookeeper or on local
                        disk
                    </li>
                </ul>
            </li>
            <li class="fragment roll-in">
                <span class="focus">Supervisor</span>
                <ul>
                    <li>Run worker processes</li>
                    <li>The supervisor listens for work assigned to its machine and starts and stops worker processes as
                        necessary based on what Nimbus has assigned to it
                    </li>
                </ul>

            </li>
        </ul>
    </section>

    <section>
        <h2>Storm Topology</h2>
        <img src="img/topology.png"/>
    </section>

    <section>
        <h2>Main Concepts</h2>
        <ul>
            <li class="fragment roll-in">
                <span class="focus">Streams</span>
                <ul>
                    <li>Unbounded sequence of tuples/datas (input or output)</li>
                </ul>
            </li>
            <li class="fragment roll-in">
                <span class="focus">Spouts</span>
                <ul>
                    <li>Source of streams</li>
                    <li>Such as reading data from Twitter Streaming API</li>
                </ul>
            </li>
            <li class="fragment roll-in">
                <span class="focus">Bolts</span>
                <ul>
                    <li>Processes input streams, does some processing and possibly emits new streams</li>
                </ul>
            </li>
            <li class="fragment roll-in">
                <span class="focus">Topologies</span>
                <ul>
                    <li>Network of spouts and bolts</li>
                </ul>
            </li>
        </ul>
    </section>
</section>

<section>
    <section>
        <h1>Slides</h1>
        <a href="https://github.com/accavdar/BigDataDemystified"
           target="_blank">https://github.com/accavdar/BigDataDemystified</a>
    </section>
</section>

<section>
    <section data-transition="linear" data-background="#4d7e65"
             data-background-transition="slide">
        <h1>THE END</h1>

        <h3 class="inverted">by Abdullah Cetin CAVDAR / <a href="http://twitter.com/accavdar"
                                                           target="_blank">@accavdar</a>
        </h3>
    </section>
</section>
</div>
</div>

<script src="reveal/lib/js/head.min.js"></script>
<script src="reveal/js/reveal.min.js"></script>

<script>
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        theme: Reveal.getQueryHash().theme,
        transition: Reveal.getQueryHash().transition || 'zoom', // default/cube/page/concave/zoom/linear/fade/none

        dependencies: [
            { src: 'reveal/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            } },
            { src: 'reveal/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            } },
            { src: 'reveal/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            } },
            { src: 'reveal/plugin/highlight/highlight.js', async: true, callback: function () {
                hljs.initHighlightingOnLoad();
            } },
            { src: 'reveal/plugin/zoom-js/zoom.js', async: true, condition: function () {
                return !!document.body.classList;
            } },
            { src: 'reveal/plugin/notes/notes.js', async: true, condition: function () {
                return !!document.body.classList;
            } }
        ]
    });
</script>
</body>
</html>
